---
title: "MEE paper use_case — Ecological stability & technological congruence"
author: "Emma Belaud"
format:
  html:
    css: css/styles.css  
    embed-resources: true
    code-tools: true
    toc: true
    toc-depth: 4
execute: 
  warning: false
  message: false
  echo: false
---

# Overview

This document provides the full reproducible analysis for the ecological use-case
section of the manuscript *"Automated processing for in situ soil monitoring: from
raw images to population dynamics"*. It addresses two integrated hypotheses:

**H1 — Ecological stability:** Arboreal linear features (Position A) act as stable
micro-refugia for soil invertebrate communities, whereas adjacent cultivated zones
(Position C) exhibit volatile, pulsed population dynamics driven by recurrent
agricultural disturbance.

**H2 — Technological congruence:** Ecological effect sizes derived from the automated
computer vision pipeline are statistically indistinguishable from those derived via
expert-validated manual classification, demonstrating that the classification pipeline
preserves the scientific narrative established by human taxonomists.

Both hypotheses are tested on the same dataset using the same statistical framework,
differing only in the source of taxonomic classification (manual vs. model-derived).
This parallelism is intentional: it allows a direct, unbiased comparison of the two
pipelines under identical analytical conditions.


```{r}
#| label: setup-env

# --- Core data wrangling and visualisation ---
library(tidyverse)    # Data manipulation (dplyr, tidyr, purrr) and plotting (ggplot2)
library(lubridate)    # Robust date-time parsing and arithmetic

# --- Statistical modelling ---
library(glmmTMB)      # Generalised Linear Mixed Models with flexible families
                      # (used here for Zero-Inflated Gamma with AR1 correlation)
library(performance)  # Model diagnostics: convergence checks
library(broom.mixed)  # Tidy extraction of fixed/random effect estimates from GLMMs

# --- Rolling window computation ---
library(slider)       # Efficient, window-based calculations on ordered sequences
                      # (used to compute the 7-day rolling CV)

# --- Residual simulation diagnostics ---
library(DHARMa)       # Simulation-based residual diagnostics for GLMMs
                      # Tests for dispersion, outliers, zero-inflation, and uniformity

# --- Reporting and visualisation utilities ---
library(kableExtra)   # Enhanced HTML/LaTeX table formatting for knitr output
library(ggrepel)      # Non-overlapping text labels in ggplot2 figures

# ─────────────────────────────────────────────────────────────────────────────
# GLOBAL COLOUR PALETTE
# Two land-use positions are colour-coded consistently throughout all figures:
#   Position A (Arboreal / tree line): muted green  → #658C58
#   Position C (Cultivated / crop zone): burnt orange → #CC561E
# This palette is perceptually distinct and print-safe (distinguishable in
# greyscale for print publication).
# ─────────────────────────────────────────────────────────────────────────────
pos_colors <- c("A" = "#658C58", "C" = "#CC561E")
pos_labels  <- c("A" = "Arboreal", "C" = "Cultivated")

# ─────────────────────────────────────────────────────────────────────────────
# PUBLICATION THEME (Methods in Ecology and Evolution style)
# Inherits from theme_minimal; removes minor gridlines for visual clarity;
# sets a compact base font size (9 pt) suitable for two-column figures.
# Applied globally via theme_set() so all subsequent plots inherit it
# without requiring explicit calls in each figure chunk.
# ─────────────────────────────────────────────────────────────────────────────
theme_mee <- function() {
  theme_minimal(base_size = 9) +
    theme(
      panel.grid.minor = element_blank(),
      strip.text       = element_text(face = "bold", size = 8),
      legend.position  = "bottom"
    )
}
theme_set(theme_mee())
```

---

# 1. Data loading & preprocessing

## 1.1 Raw classification data

The input file `combined_data.csv` is the primary output of the image processing
pipeline. Each row corresponds to a single invertebrate candidate box extracted from
a raw scanner image, and contains three fields: the image filename (which encodes all
spatiotemporal and scanner metadata), the taxon label assigned by the automated
classification model (`Model_class`), and the label assigned by a human expert
annotator (`Manual_class`). Retaining both labels in the same dataframe is what
enables the side-by-side comparison required for H2.

```{r}
#| label: data-loading

df <- read.csv("../images_analysis/DIAMS_data/combined_data.csv",
               header = FALSE, strip.white = TRUE, na.strings = "NA")
colnames(df) <- c("image_name", "Model_class", "Manual_class")

# ─────────────────────────────────────────────────────────────────────────────
# FILENAME PARSING — extracting metadata from structured filenames
#
# The image filename encodes all key metadata in a fixed format:
#   <scanner>_<YYYY-MM-DD_HHhMMm>.jp2_<extract_num>_<xmin> <ymin> <xmax> <ymax>.jpeg
#
# We use tidyr::extract() with a regex to decompose this into:
#   - scanner:      Scanner unit identifier (e.g., "DIAMS_A20_O")
#   - datetime_raw: Acquisition timestamp (resolved to 6-hour windows below)
#   - extract_num:  Index of the candidate box within that scan
#   - xmin/ymin/xmax/ymax: Bounding box pixel coordinates within the raw scan
#
# From the scanner ID, three biological/technical factors are derived:
#   - position:    Land-use treatment (A = arboreal, C = cultivated); character 4
#   - depth:       Soil depth layer (characters 5–6, in cm)
#   - orientation: Scanner spatial orientation (O = Ouest/West, E = Est/East);
#                  character 8. Two scanners per position allow replication.
# ─────────────────────────────────────────────────────────────────────────────
pattern <- "^(.*)_(\\d{4}-\\d{2}-\\d{2}_\\d{2}H\\d{2}M)\\.jp2_(\\d+)_(\\d+)\\s(\\d+)\\s(\\d+)\\s(\\d+)\\.jpeg$"

df <- df %>%
  extract(image_name,
          into  = c("scanner", "datetime_raw", "extract_num",
                    "xmin", "ymin", "xmax", "ymax"),
          regex = pattern, remove = FALSE) %>%
  mutate(
    position    = substr(scanner, 4, 4),
    depth       = substr(scanner, 5, 6),
    orientation = substr(scanner, 8, 8),
    across(c(extract_num, xmin, ymin, xmax, ymax), as.integer),
    date = ymd_hm(str_replace(datetime_raw, "_", " "))
  ) %>%

  # ── Temporal cutoff ──────────────────────────────────────────────────────
  # Data after 2024-04-09 are excluded because sensor downtime in late April
  # introduced systematic gaps that would inflate CV estimates independently
  # of biological dynamics. Retaining only the first ~33 days (March 6 –
  # April 8) ensures a continuous, high-quality time series.
  filter(date < "2024-04-09 00:00:00") %>%

  # ── Temporal standardisation to 6-hour observation windows ───────────────
  # The scanner acquires images nominally at 00:00, 06:00, 12:00, and 18:00.
  # In practice, a small sub-minute drift (e.g., 00:01) can occur. We correct
  # this by subtracting 1 minute wherever minute == 1, then filtering to
  # exact hour-marks, ensuring a perfectly regular 4-observation-per-day grid.
  mutate(
    date = if_else(minute(date) == 1, date - minutes(1), date),
    hour = hour(date),
    day  = as.Date(date)
  ) %>%
  filter(minute(date) == 0, hour %in% c(0, 6, 12, 18)) %>%

  # ── Remove mutual background detections ──────────────────────────────────
  # Rows where both classifiers agree the box is background carry no
  # biological information and would inflate image counts unnecessarily.
  # Rows where at least one classifier assigns a taxon label are retained,
  # as disagreement between classifiers is itself informative for H2.
  filter(!(Model_class == "background" & Manual_class == "background")) %>%

  select(-datetime_raw) %>%
  drop_na(date, position, Manual_class) %>%
  mutate(hour = sprintf("%02d:00", hour))
```

## 1.2 Explicit grid completion

A crucial methodological step in count-based ecological time series is to
distinguish **biological zeros** (a taxon was genuinely absent during an observation
window) from **technical gaps** (the sensor was offline and no image was acquired).
Conflating the two can severely bias temporal variability estimates: a taxon undetected
during a sensor gap would spuriously appear as a zero, inflating the CV.

We address this by creating a fully explicit spatio-temporal grid containing every
possible combination of time slot × scanner unit, then left-joining the observed
detections onto it. Rows without a matching detection receive `NA` for `image_name`,
recorded as `image_present = FALSE`. This boolean flag is later used by the rolling
stability function to apply the 5% missingness quality filter.

```{r}
#| label: data-completion

df_complete <- expand_grid(
  day         = unique(df$day),
  hour        = c("00:00", "06:00", "12:00", "18:00"),
  position    = unique(df$position),
  depth       = unique(df$depth),
  orientation = unique(df$orientation)
) %>%
  left_join(df, by = c("day", "hour", "position", "depth", "orientation")) %>%
  # image_present = TRUE  → image acquired; biological information available
  # image_present = FALSE → sensor gap; slot must not be treated as a zero count
  mutate(image_present = !is.na(image_name))
```

---

# 2. Hypothesis 1 — Ecological stability

## 2.1 Rationale and stability metric

Population stability is operationally defined as the **inverse of temporal variability**.
We quantify variability using the **Coefficient of Variation (CV)**, computed within a
rolling 7-day window (28 consecutive 6-hour observations). The CV (σ/μ) is
dimensionless, which makes it comparable across taxa with very different mean abundance
levels — a key requirement when contrasting organisms as disparate as Acari and
Lumbricidae.

A high CV indicates a "pulsed" dynamic: the population fluctuates strongly over short
periods, the expected signature of a cultivated environment. A low CV indicates a stable, buffered dynamic
consistent with the relatively undisturbed arboreal linear feature.

The 7-day window was selected as an ecologically meaningful unit 
that smooths sub-daily stochastic variation while remaining sensitive to
week-scale population pulses. A formal sensitivity analysis across window sizes from
3 to 13 days is reported to verify that the directional conclusions
are robust to this choice.

## 2.2 Rolling stability function

The function below encapsulates the full rolling CV calculation, including quality
control. It is designed to be applied independently to each taxon–scanner–position
combination via `purrr::map()`, ensuring complete analytical parallelism across the
community.

```{r}
#| label: functional-stability-prep

#' Compute Rolling CV-based Stability with Sensor Gap Quality Control
#'
#' @param data          A dataframe with columns `activity_log` (log1p-transformed
#'                      count) and `image_present` (logical: was an image acquired?).
#'                      Must be ordered chronologically before calling.
#' @param window_days   Duration of the rolling window in days (default: 7).
#'                      Converted internally to slots (window_days × slots_per_day).
#' @param slots_per_day Number of images acquired per day (default: 4, i.e. 6-hourly).
#' @param daily_step    If TRUE, returns one CV estimate per day (midnight slot only),
#'                      reducing within-day autocorrelation before GLMM fitting.
#' @param max_missing   Maximum tolerated proportion of sensor gaps within a window
#'                      (default: 0.05 = 5%). Windows exceeding this threshold are
#'                      discarded (CV set to NA) to prevent technical artefacts from
#'                      inflating apparent biological variability.
#' @return A dataframe with additional columns: `gaps_count`, `missing_rate`,
#'         `roll_mean`, `roll_sd`, and `roll_cv`.
compute_rolling_stability <- function(data, window_days = 7, slots_per_day = 4,
                                      daily_step = TRUE, max_missing = 0.05) {

  # Total number of slots to look back (exclusive of the focal slot itself)
  lookback <- (window_days * slots_per_day) - 1

  res <- data %>%
    arrange(date) %>%
    mutate(
      # ── Step 1: Quantify sensor gaps within the rolling window ────────────
      # slide_sum counts TRUE values of !image_present (i.e., absent images).
      # .complete = TRUE ensures only fully-populated windows are computed,
      # avoiding edge artefacts at the start of the time series.
      gaps_count   = slide_dbl(!image_present, sum,
                                .before = lookback, .complete = TRUE),
      missing_rate = gaps_count / (lookback + 1),

      # ── Step 2: Compute rolling mean and SD on biologically valid slots ───
      # Technical gaps are set to NA so they are excluded from mean/SD
      # calculations (na.rm = TRUE). Biological zeros (taxon absent but sensor
      # present) remain as 0 in activity_log and are included, as they represent
      # genuine absence events that contribute to population variability.
      activity_for_roll = ifelse(image_present, activity_log, NA),
      roll_mean = slide_dbl(activity_for_roll, mean, na.rm = TRUE,
                             .before = lookback, .complete = TRUE),
      roll_sd   = slide_dbl(activity_for_roll, sd,   na.rm = TRUE,
                             .before = lookback, .complete = TRUE)
    ) %>%

    # ── Step 3: Apply the 5% quality filter ──────────────────────────────────
    # CV is retained only if the proportion of missing images is within the
    # acceptable tolerance. This threshold excludes windows affected by
    # multi-day sensor outages while tolerating occasional single-slot failures
    # (e.g. file corruption). Informal checks confirmed stability of results
    # between 2.5% and 10%.
    # A small constant (+0.001) is added to the denominator to prevent
    # division-by-zero in windows where mean activity is exactly zero.
    mutate(
      roll_cv = ifelse(
        missing_rate <= max_missing,
        roll_sd / (roll_mean + 0.001),
        NA
      )
    ) %>%
    filter(!is.na(roll_cv))

  # Subsample to midnight observation only to reduce within-day autocorrelation
  # before fitting GLMMs (one CV estimate per calendar day).
  if (daily_step) res <- res %>% filter(hour(date) == 0)

  return(res)
}
```

## 2.3 Applying the stability framework

Before computing rolling CVs, raw detection counts are aggregated to the
scanner–day–time-slot level and supplemented with structural zeros. The `complete()`
call is critical: it inserts explicit `activity = 0` rows for every
taxon–scanner–slot combination where the taxon was not observed but the sensor was
operational — these are biological zeros, not missing data.

A minimum detection threshold of 10 observations per taxon excludes taxa with
insufficient data for stable CV estimation. `purrr::map()` then applies
`compute_rolling_stability()` independently within each taxon × position × 
scanner-orientation group, preserving the nested structure of the experimental
design (two scanners per position).

```{r}
#| label: apply-refined-stability

min_detections <- 10   # Minimum total records required for a taxon to be included

stability_results <- df_complete %>%

  # ── Taxon-level abundance filter ──────────────────────────────────────────
  group_by(Manual_class) %>%
  filter(n() >= min_detections) %>%
  ungroup() %>%

  mutate(image_present = !is.na(image_name)) %>%

  # ── Aggregate to scanner × date × time-slot × taxon ──────────────────────
  # n_distinct(image_name) counts unique images in each group, providing a
  # robust activity count even if the same image appears in multiple rows
  # (e.g. due to multiple detected invertebrates per scan).
  group_by(position, orientation, date, Manual_class) %>%
  summarise(
    image_present = any(image_present),
    activity      = n_distinct(image_name, na.rm = TRUE),
    .groups       = "drop"
  ) %>%

  # ── Insert biological zeros ───────────────────────────────────────────────
  # For each scanner–date–time-slot, taxa not recorded receive activity = 0.
  # nesting() carries the image_present status from the scanner-level record,
  # preventing technical gaps from being misclassified as biological absences.
  complete(
    Manual_class,
    nesting(position, orientation, date, image_present),
    fill = list(activity = 0)
  ) %>%

  # ── Log-transform activity ────────────────────────────────────────────────
  # log1p(x) = log(x + 1) handles zeros without arbitrary offsets, compresses
  # the right tail, and makes rolling mean/SD comparable across taxa.
  mutate(activity_log = log1p(activity)) %>%

  # ── Rolling stability: nested map across taxon × position × scanner ───────
  group_by(Manual_class, position, orientation) %>%
  nest() %>%
  mutate(
    rolling_data = map(data, ~compute_rolling_stability(
      .x, window_days = 7, max_missing = 0.05
    ))
  ) %>%
  unnest(rolling_data) %>%
  ungroup() %>%

  # ── Create integer time index for AR1 correlation structure ───────────────
  # glmmTMB's ar1() requires a factor-encoded, evenly spaced time index.
  # Converting date to an integer rank satisfies this requirement cleanly.
  mutate(time_idx = as.numeric(as.factor(date))) %>%
  drop_na(date, position, Manual_class) %>%

  # Remove non-invertebrate classes that passed the abundance filter
  filter(!Manual_class %in% c("background", "multi_taxa", "unknown"))
```

## 2.4 Exploratory visualisation

Before fitting models, we visualise the raw temporal dynamics for each taxon across
the four individual scanner units. Each vertical spike represents a single 6-hour
log-transformed count. The spike map allows visual inspection of the "pulsed vs.
stable" contrast that H1 seeks to formally test, and confirms that the differences
between positions are biologically interpretable rather than artefactual.

CV summary statistics (mean ± SD across the study period) are overlaid as text
annotations to provide a quantitative reference consistent with the modelling results
reported below.

```{r}
#| label: fig-activity-dynamics
#| fig-cap: "Temporal activity dynamics across four independent scanners
#|           (Position × Orientation). Each vertical spike represents a
#|           log-transformed 6-hour detection count. Text annotations give
#|           the mean (±SD) rolling CV per land-use treatment."
#| fig-width: 12
#| fig-height: 14

# ── Prepare plotting data ──────────────────────────────────────────────────
# scanner_id encodes the 4 individual scanner units (2 positions × 2 orientations),
# each assigned a distinct shade of the position colour to preserve the
# land-use colour coding while distinguishing replicate scanners within a position.
plot_data <- df_complete %>%
  filter(!Manual_class %in% c("background", "multi_taxa", "unknown")) %>%
  group_by(Manual_class) %>%
  filter(n() >= min_detections) %>%
  ungroup() %>%
  group_by(Manual_class, position, orientation, date) %>%
  summarise(activity = n_distinct(image_name, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    activity_log = log1p(activity),
    scanner_id   = interaction(position, orientation, sep = "x")
  ) %>%
  drop_na()

# Four-level colour scheme: darker/lighter pairs within each position colour
scanner_colors <- c(
  "AxO" = "#658C58",   # Arboreal West  — base green
  "AxE" = "#BBC863",   # Arboreal East  — light green
  "CxO" = "#CC561E",   # Cultivated West — base orange
  "CxE" = "#FF6500"    # Cultivated East — bright orange
)

# ── CV annotation labels ────────────────────────────────────────────────────
# Computed from stability_results and summarised per taxon × position for
# overlay on the spike map as a compact quantitative reference.
label_data <- stability_results %>%
  group_by(Manual_class, position) %>%
  summarise(
    avg_cv = mean(roll_cv, na.rm = TRUE),
    sd_cv  = sd(roll_cv,   na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(label = sprintf("CV: %.2f (±%.2f)", avg_cv, sd_cv))

ggplot(plot_data, aes(x = date, y = activity_log)) +
  geom_linerange(
    aes(ymin = 0, ymax = activity_log, color = scanner_id, group = scanner_id),
    position  = position_dodge(width = 1),
    alpha     = 0.6,
    linewidth = 1
  ) +
  geom_text(
    data = label_data,
    aes(x = as.POSIXct("2024-03-08"), y = Inf, label = label),
    vjust = 2, hjust = 0, size = 3.2, fontface = "bold", color = "black",
    inherit.aes = FALSE
  ) +
  facet_grid(Manual_class ~ position, scales = "free_y") +
  scale_color_manual(values = scanner_colors, name = "Scanner Unit (Pos × Ori)") +
  labs(
    x        = "Observation period (Spring 2024)",
    y        = "Activity magnitude (log1p counts)"
  ) +
  theme(
    panel.spacing.y  = unit(0.5, "lines"),
    strip.background = element_rect(fill = "grey95", color = NA),
    legend.position  = "bottom"
  )
```

## 2.5 Sensitivity analysis — Window duration

The choice of a 7-day rolling window is ecologically motivated but analytically
arbitrary. We test whether the directional contrast between arboreal and cultivated
positions is robust by repeating the rolling CV calculation for window sizes of
3, 5, 7, 9, 11, and 13 days. A consistent separation between positions across all
window sizes supports the 7-day choice and rules out artefactual results.

```{r}
#| label: fig-window-sensitivity
#| fig-cap: "Sensitivity of population stability (CV) to rolling window duration.
#|           The separation between arboreal (green) and cultivated (orange)
#|           positions is consistent across all tested window sizes, validating
#|           the use of the 7-day window in the main analysis."
#| fig-width: 10
#| fig-height: 8

# map_dfr iterates over each candidate window size, applies the full preprocessing
# and rolling stability pipeline, and row-binds the results into a single dataframe
# tagged with the window_size parameter for faceting.
sensitivity_test <- map_dfr(c(3, 5, 7, 9, 11, 13), function(w) {
  df_complete %>%
    filter(!Manual_class %in% c("background", "multi_taxa")) %>%
    group_by(Manual_class) %>%
    filter(n() >= min_detections) %>%
    ungroup() %>%
    mutate(image_present_binary = !is.na(image_name)) %>%
    group_by(position, orientation, date, Manual_class) %>%
    summarise(
      activity      = n_distinct(image_name, na.rm = TRUE),
      image_present = any(image_present_binary),
      .groups       = "drop"
    ) %>%
    complete(
      Manual_class,
      nesting(position, orientation, date, image_present),
      fill = list(activity = 0)
    ) %>%
    mutate(activity_log = log1p(activity)) %>%
    group_by(Manual_class, position, orientation) %>%
    nest() %>%
    mutate(
      rolling_data = map(data, ~compute_rolling_stability(
        .x, window_days = w, daily_step = TRUE, max_missing = 0.05
      ))
    ) %>%
    unnest(rolling_data) %>%
    mutate(window_size = w) %>%
    drop_na()
})

ggplot(sensitivity_test,
       aes(x = factor(window_size), y = roll_cv, fill = position, color = position)) +
  geom_boxplot(outlier.alpha = 0.2, outlier.size = 0.5, alpha = 0.6) +
  facet_grid(Manual_class ~ position, scales = "free_y") +
  scale_fill_manual(values = pos_colors) +
  scale_color_manual(values = pos_colors) +
  guides(color = "none", fill = "none") +
  labs(
    x     = "Window size (Days)",
    y     = "Rolling CV"
  )
```

---

# 3. Statistical modelling (H1)

## 3.1 Model specification

Rolling CV values are strictly positive and right-skewed, making standard Gaussian
or Poisson GLMMs inappropriate. We use **Zero-Inflated Gamma (ZIG) GLMMs** fitted
with `glmmTMB`:

- The **Gamma component** (log link) models continuous, positive CV values and captures
  the intensity of variability as a function of land-use position.
- The **zero-inflation component** accounts for structural zeros arising in highly stable
  windows where SD ≈ 0, making CV = 0 after the `roll_sd / (roll_mean + 0.001)` calculation.
- An **AR1 correlation structure** is specified as a random effect over the integer time
  index within each scanner orientation, explicitly modelling the temporal autocorrelation
  inherent in rolling-window data.
  
However, for some taxa the AR1 correlation is near-zero or the time series is too 
short for the AR1 parameters to be identifiable, producing a non-positive-
definite Hessian. In such cases, we fall back to a simpler random-intercept
model for `orientation` (no AR1), which is more numerically stable.

The fixed effect of primary interest is `positionC` — the contrast between the cultivated
zone (C) and the arboreal reference (A) on the log-link scale. A positive estimate
indicates higher CV (lower stability) in position C; a negative estimate indicates the
reverse. One model is fitted per taxon, allowing the land-use effect to vary freely
across the community.

```{r}
#| label: model-fitting-functions

# ─────────────────────────────────────────────────────────────────────────────
# PRIMARY MODEL — Full ZIG-GLMM with AR1 temporal autocorrelation
#
# Optimiser: BFGS via optim(), preferred over the default L-BFGS-B because it
# handles the AR1 rho parameter (bounded to [-1, 1]) more gracefully near
# boundaries. Iteration limits are raised from the glmmTMB defaults (300/300)
# to 2000/2000 to give the optimiser more room on flat likelihood surfaces,
# which can occur for taxa with low temporal variability or sparse counts.
# ─────────────────────────────────────────────────────────────────────────────
fit_zig_model <- function(d) {
  glmmTMB(
    roll_cv ~ position + ar1(factor(time_idx) + 0 | orientation),
    ziformula = ~position,
    family    = ziGamma(link = "log"),
    data      = d,
    control   = glmmTMBControl(
      optimizer = optim,
      optArgs   = list(method = "BFGS"),
      optCtrl   = list(iter.max = 2000, eval.max = 2000)
    )
  )
}

# ─────────────────────────────────────────────────────────────────────────────
# SAFE MODEL FITTER — with automatic fallback for convergence failures
#
# The fitted model object receives a `model_type` attribute ("Full AR1" or
# "Fallback RI") so that the diagnostic table can flag which taxa used the
# simplified structure.
# ─────────────────────────────────────────────────────────────────────────────
fit_zig_model_safe <- function(d) {

  # ── Attempt 1: Full AR1 model ─────────────────────────────────────────────
  m_full <- tryCatch(
    fit_zig_model(d),
    error = function(e) NULL
  )

  # Check convergence via Hessian inspection; treat check errors as failure
  converged_full <- if (!is.null(m_full)) {
    tryCatch(as.logical(performance::check_convergence(m_full)),
             error = function(e) FALSE)
  } else FALSE

  if (converged_full) {
    attr(m_full, "model_type") <- "Full AR1"
    return(m_full)
  }

  # ── Attempt 2: Fallback — random intercept only, no AR1 ──────────────────
  # Applied when the full AR1 model fails to converge. Less temporally precise
  # but numerically stable; flagged clearly in the diagnostic table.
  message(sprintf("AR1 model did not converge for this taxon — fitting fallback (random intercept) model."))

  m_fallback <- tryCatch(
    glmmTMB(
      roll_cv ~ position + (1 | orientation),
      ziformula = ~position,
      family    = ziGamma(link = "log"),
      data      = d
    ),
    error = function(e) NULL
  )

  if (!is.null(m_fallback)) {
    attr(m_fallback, "model_type") <- "Fallback RI"
  }
  return(m_fallback)
}
```

```{r}
#| label: zero-inflated-models

# ── Fit models for all taxa ───────────────────────────────────────────────────
# fit_zig_model_safe() is mapped over each taxon subset.
# possibly() catches any remaining failures (NULL) that slip through
# fit_zig_model_safe() itself, preventing the pipeline from halting.
# NULL models are filtered out before result extraction.
taxon_analysis <- stability_results %>%
  group_by(Manual_class) %>%
  nest() %>%
  mutate(model = map(data, possibly(fit_zig_model_safe, otherwise = NULL))) %>%
  filter(!map_lgl(model, is.null))

# ── Extract model_type attribute from each fitted model ──────────────────────
# This records whether each taxon used the full AR1 or fallback RI structure.
taxon_analysis <- taxon_analysis %>%
  mutate(
    model_type = map_chr(model, ~attr(.x, "model_type") %||% "Full AR1")
  )

# ── Extract fixed-effect estimates across all taxa ───────────────────────────
# broom.mixed::tidy() returns a tidy tibble of model coefficients.
# We unnest across all taxa to obtain a single comparative dataframe.
model_summaries <- taxon_analysis %>%
  mutate(tidied = map(model, tidy, effects = "fixed")) %>%
  unnest(tidied)
```

## 3.2 Model diagnostics

Goodness-of-fit is assessed using **DHARMa**, which generates simulation-based
residual envelopes and tests for: (i) overdispersion, (ii) outliers,
(iii) zero-inflation misspecification, and (iv) non-uniformity of scaled residuals.
Convergence is verified via `performance::check_convergence()`.

```{r}
#| label: validation-function

#' Run DHARMa diagnostics on a fitted glmmTMB model
#'
#' @param model A fitted glmmTMB object (or NULL, which returns NULL).
#' @return A one-row tibble with convergence status and DHARMa test p-values.
validate_taxon_model <- function(model) {
  if (is.null(model)) return(NULL)

  # ── Convergence check ────────────────────────────────────────────────────
  # A non-positive-definite Hessian indicates the optimiser did not reach a
  # proper maximum. Estimates from non-converged models are retained but
  # flagged as "Non-Convergence" in the Status column.
  conv <- tryCatch(
    as.logical(performance::check_convergence(model)),
    error = function(e) FALSE
  )

  # ── DHARMa simulation-based residual diagnostics ─────────────────────────
  # 500 simulations provide a stable envelope without excessive runtime.
  sim_res <- DHARMa::simulateResiduals(model, n = 500, plot = FALSE)

  tibble(
    converged       = conv,
    p_dispersion    = DHARMa::testDispersion(sim_res,    plot = FALSE)$p.value,
    p_outlier       = DHARMa::testOutliers(sim_res,      plot = FALSE)$p.value,
    p_zero_infl     = DHARMa::testZeroInflation(sim_res, plot = FALSE)$p.value,
    p_ks_uniformity = DHARMa::testUniformity(sim_res,    plot = FALSE)$p.value
  )
}
```

The table below summarises all diagnostic metrics. A significant KS uniformity
p-value (< 0.05) for some taxa (e.g., Collembola, Enchytraeidae) reflects the
discrete, integer-count origin of the underlying data — this is expected and does
not invalidate inference on the land-use fixed effect.

| Column | Description | Ecological interpretation |
|---|---|---|
| Effect_Size | log-ratio of CV: Position C vs. A | Positive = more variable (less stable) in cultivated zone |
| KS_Unif | Kolmogorov–Smirnov uniformity p-value | p < 0.05 for integer-count taxa is expected; not a failure |
| Dispersion | DHARMa dispersion test p-value | p < 0.05 indicates Gamma variance assumption may be violated |


```{r}
#| label: batch-validation

validation_summary <- taxon_analysis %>%
  mutate(
    # ── 1. Sample size ──────────────────────────────────────────────────────
    n_obs    = map_int(model, ~nobs(.x)),
    df_resid = map_int(model, ~df.residual(.x)),

    # ── 2. DHARMa residual diagnostics ──────────────────────────────────────
    diag = map(model, validate_taxon_model),

    # ── 3. Fixed-effect estimate for positionC ───────────────────────────────
    # Filter to the conditional (Gamma) component and the positionC term,
    # discarding the intercept and zero-inflation component estimates.
    estimates = map(model, ~broom.mixed::tidy(.x, effects = "fixed") %>%
                      filter(term == "positionC", component == "cond"))
  ) %>%
  unnest(c(diag, estimates)) %>%

  mutate(
    # ── Model status — priority: convergence > dispersion > uniformity ───────
    # "Non-Convergence" is the most severe flag; "Fallback RI" taxa have a
    # simplified random structure and their AR1 estimates should not be compared
    # directly with full-model taxa.
    # "Discrete/Non-Uniform" is expected for integer-count taxa and is not
    # treated as a model failure for inference on the fixed effect.
    status = case_when(
      !converged             ~ "Non-Convergence",
      model_type == "Fallback RI" ~ "Fallback RI (no AR1)",
      p_dispersion    < 0.05 ~ "Overdispersed",
      p_ks_uniformity < 0.05 ~ "Discrete/Non-Uniform",
      TRUE                   ~ "Robust"
    ),
    sig_label = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01  ~ "**",
      p.value < 0.05  ~ "*",
      TRUE            ~ "ns"
    )
  ) %>%
  select(
    Taxon      = Manual_class,
    N          = n_obs,
    DF         = df_resid,
    Status     = status,
    Effect     = estimate,
    SE         = std.error,
    P_Val      = p.value,
    Sig        = sig_label,
    KS_Unif    = p_ks_uniformity,
    Dispersion = p_dispersion
  )
```


```{r}
#| label: tbl-validation-styled
#| tbl-cap: "Summary of Zero-Inflated Gamma models: ecological effect sizes and
#|           DHARMa diagnostics. \nTaxa are ordered from the largest to the smallest
#|           land-use effect (Position C vs. A). \nEffect sizes are on the log-link
#|           scale: positive values indicate lower stability (higher CV) in the
#|           cultivated zone. \nModel Status: 'Robust' = all DHARMa checks passed;
#|           'Fallback RI' = AR1 model did not converge and a random-intercept model
#|           was used instead; 'Discrete/Non-Uniform' = expected
#|           for integer-count taxa and is not indicative of model misspecification."

# ── Save the arranged table for row_spec indexing ────────────────────────────
# IMPORTANT: row_spec() uses row positions in the *rendered* table, not the
# original dataframe. We must therefore compute the highlight rows AFTER
# arrange(), using the arranged object directly. Referencing
# validation_summary$Status before arranging would give wrong row numbers.
tbl_arranged <- validation_summary %>%
  arrange(desc(Effect))

# Identify rows requiring visual flagging in the final arranged order
rows_fallback <- which(tbl_arranged$Status == "Fallback RI (no AR1)")

tbl_arranged %>%
  kbl(
    digits    = 3,
    booktabs  = TRUE,
    col.names = c("Taxon", "N", "DF", "Model Status",
                  "Estimate", "SE", "p-value", "Sig",
                  "KS Unif.", "Dispersion")
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width        = FALSE,
    latex_options     = "scale_down"   # Prevents overflow in two-column PDF layout
  ) %>%
  column_spec(3, bold = TRUE) %>%
  # Light blue highlight for fallback RI rows — AR1 structure absent
  row_spec(rows_fallback, background = "#ffe0e0") %>%
  add_header_above(c(
    " "                          = 4,
    "Ecological effect (Pos. C)" = 4,
    "DHARMa P-values"            = 2
  ))
```

## 3.3 Results

The forest plot below provides the primary visualisation for H1. Each row represents
one taxon; the point is the maximum-likelihood estimate of the Position C coefficient
(log-link scale), and the horizontal bars span the 95% Wald confidence interval
(estimate ± 1.96 × SE). Points to the right of zero indicate lower stability in the
cultivated zone; the single point to the left (Symphyla) indicates the reverse.
Colour distinguishes statistically significant effects (p < 0.05; red) from
non-significant ones (grey; Julida only).


```{r}
#| label: fig-h1-forest-plot
#| fig-cap: "Effect of land use (Position C vs. A) on population stability
#|           (inverse CV). Points show glmmTMB log-link estimates; horizontal
#|           bars span 95% Wald confidence intervals. Red: significant
#|           (p < 0.05); grey: non-significant."
#| fig-width: 5
#| fig-height: 4

plot_data_h1 <- model_summaries %>%
  filter(component == "cond", term == "positionC") %>%
  mutate(
    sig          = ifelse(p.value < 0.05, "Significant", "Non-significant"),
    Manual_class = reorder(Manual_class, estimate)   # Order taxa by effect size
  )

p1 <- ggplot(plot_data_h1, aes(x = estimate, y = Manual_class, color = sig)) +
  geom_vline(xintercept = 0, color = "grey50", linewidth = 0.5) +
  geom_errorbarh(
    aes(xmin = estimate - 1.96 * std.error,
        xmax = estimate + 1.96 * std.error),
    height = 0.2, linewidth = 0.8
  ) +
  geom_point(size = 2) +
  scale_color_manual(
    values = c("Significant" = "#ff6666", "Non-significant" = "#bcbcbc")
  ) +
  scale_y_discrete(expand = expansion(mult = c(0.15, 0.05))) +
  theme(
    legend.title    = element_text(size = 4),
    legend.text     = element_text(size = 4),
    legend.key.size = unit(0.01, "cm")
  ) +
  labs(
    x     = "Estimate (log-link scale)",
    y     = NULL,
    color = "Statistical status"
  ) +
  annotate("text", x =  0.5, y = 0.3, label = "Lower stability in C →",
           fontface = "italic", size = 2) +
  annotate("text", x = -0.5, y = 0.3, label = "← Lower stability in A",
           fontface = "italic", size = 2)

p1

# Export at 300 dpi for manuscript submission (MEE requires TIFF)
png("../images_analysis/output/Fig.H1_population_stability_across_position.png",
    width = 1000, height = 1000, res = 300)
p1
invisible(dev.off())
```

```{r}
#| label: tbl-h1-results
#| tbl-cap: "Generalized Linear Mixed Model (ZIG) parameters for the effect of land-use position on population stability (rolling CV). Estimates are on the log-link scale, where positive values indicate higher variability (lower stability) in cultivated zones."

plot_data_h1 %>%
  ungroup() %>%
  select(Manual_class, estimate, std.error, statistic, p.value, sig) %>%
  mutate(
    Manual_class = str_to_title(Manual_class),
    p.value = scales::pvalue(p.value) # Formats small p-values as <0.001
  ) %>%
  arrange(desc(estimate)) %>%
  kbl(
    digits = 3,
    booktabs = TRUE,
    col.names = c("Taxon", "Estimate", "Std. Error", "z-value", "p-value", "Significance")
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE,
    latex_options = "hold_position"
  ) %>%
  column_spec(1, italic = TRUE) %>%
  column_spec(6, color = ifelse(plot_data_h1$sig == "Significant", "#ff6666", "#bcbcbc"))
```

---

# 4. Hypothesis 2 — Technological congruence

## 4.1 Rationale

H2 tests whether the automated pipeline can be trusted to replace manual classification
for ecological inference. The key question is not whether the model produces identical
counts to a human expert — it will not — but whether the **downstream ecological effect
sizes** are preserved. If the land-use effect estimated from model-classified data is
congruent with the effect estimated from manually classified data, the pipeline can be
considered ecologically valid.

We assess congruence using a **1:1 identity plot**: taxa falling on or near the y = x
line show perfect agreement; systematic deviations reveal directional biases in the
automated classifier.

## 4.2 Replicating the H1 pipeline on model-classified data

The identical preprocessing, rolling stability, and GLMM workflow from H1 is applied
here, substituting `Model_class` for `Manual_class` as the taxonomic classification
source. This procedural parallelism is essential: any difference in the resulting
effect sizes must be attributable to classification accuracy, not to analytical choices.

```{r}
#| label: model-class-pipeline

# ── Exact replication of the H1 pipeline using model-derived classifications ──
# All parameters (window size, quality filter, model family, fallback logic)
# are identical to Section 3 to ensure a fair comparison.
stability_model_classification <- df_complete %>%
  group_by(Model_class) %>%
  filter(n() >= min_detections) %>%
  ungroup() %>%
  mutate(image_present_binary = !is.na(image_name)) %>%
  group_by(position, orientation, date, Model_class) %>%
  summarise(
    image_present = any(image_present_binary),
    activity      = n_distinct(image_name, na.rm = TRUE),
    .groups       = "drop"
  ) %>%
  complete(
    Model_class,
    nesting(position, orientation, date, image_present),
    fill = list(activity = 0)
  ) %>%
  mutate(activity_log = log1p(activity)) %>%
  group_by(Model_class, position, orientation) %>%
  nest() %>%
  mutate(
    rolling_data = map(data, ~compute_rolling_stability(
      .x, window_days = 7, max_missing = 0.05
    ))
  ) %>%
  unnest(rolling_data) %>%
  ungroup() %>%
  mutate(time_idx = as.numeric(as.factor(date))) %>%
  drop_na(date, position, Model_class) %>%
  filter(!Model_class %in% c("background", "multi_taxa", "unknown"))

# Fit the same safe ZIG-GLMM structure to model-derived stability series
taxon_analysis_classification <- stability_model_classification %>%
  group_by(Model_class) %>%
  nest() %>%
  mutate(model = map(data, possibly(fit_zig_model_safe, otherwise = NULL))) %>%
  filter(!map_lgl(model, is.null))
```

## 4.3 Extracting and comparing effect sizes

Fixed-effect estimates for `positionC` are extracted from both the manual and
model-derived pipelines and joined by taxon. The absolute difference (|Δ|)
quantifies the per-taxon discrepancy. Taxa with |Δ| close to zero are perfectly
congruent; larger values indicate where the automated classifier introduces the
most bias in ecological inference. Only taxa present in both pipelines (inner join)
are included, ensuring the comparison is always perfectly paired.

```{r}
#| label: h2-comparison-stats

# ── Extract positionC estimates from manual-classification models ─────────────
res_manual <- taxon_analysis %>%
  mutate(tidied = map(model, tidy, effects = "fixed")) %>%
  unnest(tidied) %>%
  filter(component == "cond", term == "positionC") %>%
  select(Taxon = Manual_class, est_man = estimate, se_man = std.error)

# ── Extract positionC estimates from model-classification models ──────────────
res_classification <- taxon_analysis_classification %>%
  mutate(tidied = map(model, tidy, effects = "fixed")) %>%
  unnest(tidied) %>%
  filter(component == "cond", term == "positionC") %>%
  select(Taxon = Model_class,
         est_classification = estimate,
         se_classification  = std.error)

# ── Join and compute per-taxon absolute discrepancy ──────────────────────────
h2_data <- inner_join(res_manual, res_classification, by = "Taxon") %>%
  mutate(diff = abs(est_man - est_classification))
```

## 4.4 Results

```{r}
#| label: fig-h2-congruence
#| fig-cap: "Technological congruence (H2): land-use effect sizes (Position C
#|           vs. A) from the manual and automated pipelines. The grey line is
#|           the 1:1 identity reference. Error bars span ± 1 SE. Taxa close to
#|           the identity line show high cross-pipeline agreement."
#| fig-width: 5
#| fig-height: 4

p2 <- ggplot(h2_data, aes(x = est_man, y = est_classification)) +
  # 1:1 reference line — the target for perfect congruence
  geom_abline(slope = 1, intercept = 0, color = "grey50", linewidth = 0.5) +
  # SE error bars for model-derived estimates (vertical axis)
  geom_errorbar(
    aes(ymin = est_classification - se_classification,
        ymax = est_classification + se_classification),
    color = "#ff6666", width = 0, linewidth = 0.5
  ) +
  # SE error bars for manual estimates (horizontal axis)
  geom_errorbarh(
    aes(xmin = est_man - se_man, xmax = est_man + se_man),
    color = "#ff6666", height = 0, linewidth = 0.5
  ) +
  geom_point(size = 2, color = "#ff6666") +
  # Non-overlapping taxon labels to avoid overplotting
  ggrepel::geom_text_repel(aes(label = Taxon), size = 2,
                            vjust = 0.3, hjust = 0.5) +
  labs(
    x = "Human estimated effect",
    y = "Model estimated effect"
  )

p2

png("../images_analysis/output/Fig.H2_technological_congruence.png",
    width = 1000, height = 1000, res = 300)
p2
invisible(dev.off())
```

```{r}
#| label: tbl-h2-congruence
#| tbl-cap: "Comparison of ecological effect size estimates between human taxonomists and the automated classification pipeline. 'Diff' represents the absolute discrepancy between manual and model-derived estimates."

h2_data %>%
  ungroup() %>%
  mutate(
    Taxon = str_to_title(Taxon),
    across(where(is.numeric), round, 3)
  ) %>%
  select(Taxon, est_man, se_man, est_classification, se_classification, diff) %>%
  kbl(
    booktabs = TRUE,
    col.names = c("Taxon", "Est (Human)", "SE (Human)", "Est (Model)", "SE (Model)", "Abs. Diff")
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE
  ) %>%
  column_spec(1, italic = TRUE) %>%
  column_spec(6, bold = TRUE) %>%
  add_header_above(c(" " = 1, "Manual Pipeline" = 2, "Model Pipeline" = 2, " " = 1))
```

