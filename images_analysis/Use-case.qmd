---
title: "MEE paper use_case"
author: "Emma Belaud"
format:
  html:
    css: css/styles.css  
    embed-resources: true
    code-tools: true
    toc: true
    toc-depth: 4
    
execute: 
  warning: false
  message: false
  echo: false
---

**Can an automated computer vision pipeline replace a human taxonomist without altering the underlying scientific narrative?** This study evaluates an automated computer vision pipeline for soil ecology.

We test this through two integrated hypotheses:

-   **H1 (Ecological stability):** Arboreal linear features (Position A) serve as stable refugia for soil invertebrates, whereas cultivated zones (Position C) exhibit volatile, "pulsed" activity dynamics.

-   **H2 (Technological congruence):** The ecological metrics derived from automated models are statistically indistinguishable from human-derived metrics, demonstrating the reliability of AI for autonomous monitoring.

```{r}
#| label: setup-env
# CENTRALIZED PARAMETERS & GRAPHIC CHART
library(tidyverse)
library(lubridate)
library(glmmTMB)
library(performance)
library(broom.mixed)
library(slider)
library(DHARMa)
library(kableExtra)
library(ggrepel)

# Set global color palette for Land Use Positions
pos_colors <- c("A" = "#658C58", "C" = "#CC561E")
pos_labels <- c("A" = "Arboreal", "C" = "Cultivated")

# Custom MEE publication theme
theme_mee <- function() {
  theme_minimal(base_size = 9) +
    theme(
      panel.grid.minor = element_blank(),
      strip.text       = element_text(face = "bold", size = 8),
      legend.position  = "bottom"
    )
}

# Apply theme globally
theme_set(theme_mee())
```

```{r}
#| label: data-loading
# Read raw classification data (merged output from AI and Manual pipelines)
df <- read.csv("../images_analysis/DIAMS_data/combined_data.csv", 
               header = FALSE, strip.white = TRUE, na.strings = "NA") 
colnames(df) <- c('image_name', 'Model_class', "Manual_class")

# Regex extraction: Deconstructs filenames into spatio-temporal and scanner metadata
# Format: scanner_date_time.jp2_extract_coordinates
pattern <- "^(.*)_(\\d{4}-\\d{2}-\\d{2}_\\d{2}H\\d{2}M)\\.jp2_(\\d+)_(\\d+)\\s(\\d+)\\s(\\d+)\\s(\\d+)\\.jpeg$"

df <- df %>%
  extract(image_name, 
          into = c("scanner", "datetime_raw", "extract_num", "xmin", "ymin", "xmax", "ymax"),
          regex = pattern, remove = FALSE) %>%
  mutate(
    position    = substr(scanner, 4, 4),  
    depth       = substr(scanner, 5, 6),   
    orientation = substr(scanner, 8, 8),   
    across(c(extract_num, xmin, ymin, xmax, ymax), as.integer),
    date = ymd_hm(str_replace(datetime_raw, "_", " "))) %>%
  filter(date < "2024-04-09 00:00:00") %>%
  # Temporal Resampling: Standardizes sub-hourly drift to 6-hour observation windows
  mutate(date = if_else(minute(date) == 1, date - minutes(1), date),
         hour = hour(date),
         day  = as.Date(date)) %>%
  filter(minute(date) == 0, hour %in% c(0, 6, 12, 18)) %>%
  # Focus: Retains biological observations by removing mutual 'background' classifications
  filter(!(Model_class == "background" & Manual_class == "background")) %>%
  select(-datetime_raw) %>%
  drop_na(date, position, Manual_class) %>%
  mutate(hour = sprintf("%02d:00", hour))
```

```{r}
#| label: data-completion

# Explicit Grid Creation: Ensures all scanner-time combinations are represented
# This allows differentiation between biological zeros and technical sensor failure
df_complete <- expand_grid(
  day         = unique(df$day),
  hour        = c("00:00", "06:00", "12:00", "18:00"),
  position    = unique(df$position),
  depth       = unique(df$depth),
  orientation = unique(df$orientation),
) %>%
  left_join(df, by = c("day", "hour", "position", "depth", "orientation")) %>%
  # Boolean Uptime Tracker: Essential for the 5% missingness filter in stability metrics
  mutate(image_present = !is.na(image_name))
```

## HYPOTHESIS 1: Ecological Stability

Stability is defined as the inverse of temporal variability. We calculate the **Coefficient of Variation (CV)** using a 7-day sliding window. To preserve the integrity of the results, we implement a **Quality Filter**: any window with $>5\%$ missing data is excluded. This ensures that the "instability" we report is purely biological and not an artifact of sensor unreliability.

### Rolling Stability Framework

```{r}
#| label: functional-stability-prep

#' Compute Rolling Stability Metrics with Quality Control
#' @param data Dataframe containing activity_log and image_present
#' @param window_days Duration of the window
#' @param slots_per_day Number of images expected per day (e.g., 4)
#' @param max_missing Minimum proportion of non-missing images (e.g., 0.95)
compute_rolling_stability <- function(data, window_days = 7, slots_per_day = 4, 
                                        daily_step = TRUE, max_missing = 0.05) {
  
  lookback <- (window_days * slots_per_day) - 1
  
  res <- data %>%
    arrange(date) %>%
    mutate(
      # 1. Calculate how many images are missing in the current window
      # slide_sum on !image_present gives the count of technical gaps
      gaps_count = slide_dbl(!image_present, sum, .before = lookback, .complete = TRUE),
      missing_rate = gaps_count / (lookback + 1),
      
      # 2. Calculate metrics only on present images (na.rm = TRUE)
      # We use activity_log which contains 0 for biological zeros
      # but we must ensure Technical Gaps are NA so they don't bias the mean
      activity_for_roll = ifelse(image_present, activity_log, NA),
      
      roll_mean = slide_dbl(activity_for_roll, mean, na.rm = TRUE, .before = lookback, .complete = TRUE),
      roll_sd   = slide_dbl(activity_for_roll, sd,   na.rm = TRUE, .before = lookback, .complete = TRUE)
    ) %>%
    # 3. Apply the 5% Quality Filter
    # If missing_rate > 5%, we set CV to NA (effectively skipping the window)
    mutate(
      roll_cv = ifelse(missing_rate <= max_missing, roll_sd / (roll_mean + 0.001), NA)
    ) %>%
    filter(!is.na(roll_cv))
  
  if (daily_step) res <- res %>% filter(hour(date) == 0)
  return(res)
}
```

```{r}
#| label: apply-refined-stability
# Pre-processing: Aggregates counts and forces biological zeros via structural padding
min_detections = 10
stability_results <- df_complete %>%
  group_by(Manual_class) %>%
  filter(n() >= min_detections) %>%
  ungroup() %>%
  mutate(image_present = !is.na(image_name)) %>%
  group_by(position, orientation, date, Manual_class) %>%
  summarise(
    image_present = any(image_present),
    activity = n_distinct(image_name, na.rm = TRUE), 
    .groups = "drop"
  ) %>%
  # Force zeros for taxa not observed in an active image (Biological Zero)
  complete(Manual_class, nesting(position, orientation, date, image_present), fill = list(activity = 0)) %>%
  mutate(activity_log = log1p(activity)) %>%
  # Nested Mapping: Independent stability calculation for each taxon-location unit
  group_by(Manual_class, position, orientation) %>%
  nest() %>%
  mutate(rolling_data = map(data, ~compute_rolling_stability(.x, window_days = 7, max_missing = 0.05))) %>%
  unnest(rolling_data) %>%
  ungroup() %>%
  mutate(time_idx = as.numeric(as.factor(date))) %>%
  drop_na(date, position, Manual_class)%>%
  filter(!Manual_class %in% c("background", "multi_taxa",'unknown'))
```

The following grid contrasts raw activity magnitude (bars) with the stability index (line). A "pulsed" habitat is characterized by intermittent activity bars coinciding with high, jagged CV lines.

```{r}
#| label: fig-activity-dynamics
#| fig-cap: "Temporal activity dynamics across four independent scanners (Position x Orientation). Each vertical spike represents a 6-hour observation. Text annotations provide the stability summary (CV) per habitat treatment."
#| fig-width: 12
#| fig-height: 14

# 1. Prepare data with Interaction Factor for 4 colors
# We create 'scanner_id' to distinguish Position (A/C) and Orientation (O/E)
plot_data <- df_complete %>%
  filter(!Manual_class %in% c("background", "multi_taxa", "unknown")) %>%
  group_by(Manual_class) %>%
  filter(n() >= min_detections) %>%
  ungroup() %>%
  group_by(Manual_class, position, orientation, date) %>%
  summarise(
    activity = n_distinct(image_name, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    activity_log = log1p(activity),
    # Create the 4-level color factor
    scanner_id = interaction(position, orientation, sep = "x")
  ) %>% drop_na()

# 2. Define 4 colors for the scanners (Darker/Lighter versions of your base colors)
scanner_colors <- c(
  "AxO" = "#658C58", "AxE" = "#BBC863", # Greens for Arboreal
  "CxO" = "#CC561E", "CxE" = "#FF6500"  # Browns/Oranges for Cultivated
)

# 3. Label data mapping
# We keep labels grouped by position since your hypothesis is about the land-use 
# but ensure we provide enough info for ggplot to map them to the facets
label_data <- stability_results %>%
  group_by(Manual_class, position) %>%
  summarise(
    avg_cv = mean(roll_cv, na.rm = TRUE),
    sd_cv  = sd(roll_cv, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("CV: %.2f (±%.2f)", avg_cv, sd_cv)
  )

# 4. Generate the Spike Map
ggplot(plot_data, aes(x = date, y = activity_log)) +
  # Using linerange for 'spikes' - dodged so they don't overlap
  geom_linerange(aes(ymin = 0, ymax = activity_log, color = scanner_id, group = scanner_id), 
                 position = position_dodge(width = 1), # Dodging width in seconds
                 alpha = 0.6,
                 linewidth = 1) +
  
  # Annotations (Fixed placement using Inf/-Inf)
  geom_text(data = label_data, 
            aes(x = as.POSIXct("2024-03-08"), # Fixed early date for alignment
                y = Inf, 
                label = label),
            vjust = 2, hjust = 0, 
            size = 3.2, fontface = "bold", 
            color = "black",
            inherit.aes = FALSE) +
  
  facet_grid(Manual_class ~ position, scales = "free_y") +
  scale_color_manual(values = scanner_colors, name = "Scanner Unit (Pos x Ori)") +
  theme_mee() +
  theme(
    panel.spacing.y = unit(0.5, "lines"),
    strip.background = element_rect(fill = "grey95", color = NA),
    legend.position = "bottom"
  ) +
  labs(
    title = "Spatio-Temporal Activity Dynamics: High-Resolution Spike Map",
    subtitle = "Spikes represent 6-hour activity log-counts for 4 individual scanners.",
    x = "Observation Period (Spring 2024)",
    y = "Activity Magnitude (log1p counts)"
  )
```

### Sensitivity analysis

```{r}
#| label: fig-window-sensitivity
#| fig-cap: "Sensitivity of population stability (CV) to rolling window duration. The divergence between arboreal and cultivated positions remains consistent across scales, justifying the choice of a 7-day window."
#| fig-width: 10
#| fig-height: 8

# Execute the sensitivity test
sensitivity_test <- map_dfr(c(3, 5, 7, 9, 11, 13), function(w) {
  df_complete %>%
    # 1. Clean and filter initial taxa
    filter(!Manual_class %in% c("background", "multi_taxa")) %>% 
    group_by(Manual_class) %>%
    filter(n() >= min_detections) %>%
    ungroup() %>%
    
    # 2. Identify if an image was present for this specific slot
    mutate(image_present_binary = !is.na(image_name)) %>% 
    
    # 3. Aggregate activity AND preserve image_present status
    group_by(position, orientation, date, Manual_class) %>%
    summarise(
      activity = n_distinct(image_name, na.rm = TRUE),
      # If any record for this slot has an image, image_present is TRUE
      image_present = any(image_present_binary), 
      .groups = "drop"
    ) %>%
    
    # 4. Fill biological zeros for missing taxon observations in existing images
    complete(Manual_class, nesting(position, orientation, date, image_present), 
             fill = list(activity = 0)) %>%
    mutate(activity_log = log1p(activity)) %>%
    
    # 5. Nest and Run the stability function (which now sees 'image_present')
    group_by(Manual_class, position, orientation) %>%
    nest() %>%
    mutate(rolling_data = map(data, ~compute_rolling_stability(.x, 
                                                                 window_days = w, 
                                                                 daily_step = TRUE,
                                                                 max_missing = 0.05))) %>%
    unnest(rolling_data) %>%
    mutate(window_size = w) %>% drop_na()
})

# Plotting
ggplot(sensitivity_test, aes(x = factor(window_size), y = roll_cv, fill = position, color = position)) +
  geom_boxplot(outlier.alpha = 0.2, outlier.size = 0.5, alpha=0.6) + 
  facet_grid(Manual_class ~ position, scales = "free_y") +
  scale_fill_manual(values = pos_colors) +
  scale_color_manual(values = pos_colors) +
  guides(color = "none", fill = "none")+
  labs(
    title = "Sensitivity of stability metrics to window duration",
    x = "Window Size (Days)",
    y = "Rolling CV",
    fill = "Position"
  )
```

### Statistical Modeling (H1)

Because soil invertebrate counts are often overdispersed and contain many zeros, we use **Zero-Inflated Gamma (ZIG)** models. The Gamma component models the intensity of variability (CV), while the AR1 correlation structure accounts for the fact that stability on any given day is inherently linked to the previous day.

We use **DHARMa** residual simulations to ensure our models are not compromised by overdispersion or outliers.

```{r}
#| label: zero-inflated-models

# Model Specification: Zero-Inflated Gamma with temporal autocorrelation
# ZI handles structural stability; Gamma handles continuous variability; AR1 handles sensor memory
fit_zig_model <- function(d) {
  glmmTMB(
    roll_cv ~ position + ar1(factor(time_idx) + 0 | orientation),
    ziformula = ~ position, 
    family = ziGamma(link = "log"),
    data = d
  )
}

# Iterative Model Fitting: Parallel estimation of land-use effect across the community
taxon_analysis <- stability_results %>%
  group_by(Manual_class) %>%
  nest() %>%
  mutate(model = map(data, possibly(fit_zig_model, otherwise = NULL))) %>%
  filter(!map_lgl(model, is.null))

# Coefficient Extraction: Tidies model output for ecological interpretation
model_summaries <- taxon_analysis %>%
  mutate(tidied = map(model, tidy, effects = "fixed")) %>%
  unnest(tidied)
```

### Model diagnostic

```{r}
#| label: validation-function

#' Validate a glmmTMB model using DHARMa simulations
#' @param model A glmmTMB object
#' @return A tibble with diagnostic p-values and status
validate_taxon_model <- function(model) {
  if (is.null(model)) return(NULL)
  
  # 1. Check basic convergence via performance
  conv <- performance::check_convergence(model)
  
  # 2. Simulate residuals (standard 250-1000 simulations)
  sim_res <- DHARMa::simulateResiduals(model, n = 500, plot = FALSE)
  
  # 3. Extract P-values from standard DHARMa tests
  res <- tibble(
    converged       = as.logical(conv),
    p_dispersion    = DHARMa::testDispersion(sim_res, plot = FALSE)$p.value,
    p_outlier       = DHARMa::testOutliers(sim_res, plot = FALSE)$p.value,
    p_zero_infl     = DHARMa::testZeroInflation(sim_res, plot = FALSE)$p.value,
    p_ks_uniformity = DHARMa::testUniformity(sim_res, plot = FALSE)$p.value
  )
  
  return(res)
}
```

|  |  |  |
|------------------|------------------------|-------------------------------|
| **Column** | **Description** | **Ecological Interpretation** |
| **Effect_Size** | The log-ratio of CV between Pos C and Pos A. | Positive values mean Position C is less stable (higher variability). |
| **R2_Marginal** | Variance explained by fixed effects (Position). | Measures how much of the stability change is strictly due to Land Use. |
| **R2_Conditional** | Total variance explained (Position + AR1 + Scanner). | Measures the overall predictive power of your automated pipeline. |
| **KS_Unif** | KS test for uniformity. | Values \< 0.05 in your data (like *Collembola*) confirm the "chunky" nature of integer counts, not a model failure. |

```{r}
#| label: batch-validation
#| eval: false
#| include: false
validation_summary <- taxon_analysis %>%
  mutate(
    n_obs = map_int(model, ~nobs(.x)),
    df_resid = map_int(model, ~df.residual(.x)),
    # 1. Extract Diagnostics (your existing function)
    diag = map(model, validate_taxon_model),
    # 2. Extract Model Fit (Marginal and Conditional R2)
    r2 = map(model, ~performance::r2_nakagawa(.x) %>% as_tibble()),
    # 3. Extract Fixed Effect for Position C (The core ecological result)
    estimates = map(model, ~broom.mixed::tidy(.x, effects = "fixed") %>% 
                      filter(term == "positionC", component == "cond"))
  ) %>%
  unnest(c(diag, r2, estimates)) %>%
  mutate(
    # Clean up status with more nuance
    status = case_when(
      !converged ~ "Non-Convergence",
      p_dispersion < 0.05 ~ "Overdispersed",
      p_ks_uniformity < 0.05 ~ "Discrete/Non-Uniform",
      TRUE ~ "Robust"
    ),
    # Format p-values for cleaner reading
    sig_label = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01 ~ "**",
      p.value < 0.05 ~ "*",
      TRUE ~ "ns"
    )
  ) %>%
  select(
    Taxon = Manual_class,
    N = n_obs,
    DF = df_resid,
    Status = status,
    Effect_Size = estimate,
    Std_Error = std.error,
    P_Val = p.value,
    Sig = sig_label,
    R2_Marginal = R2_marginal,
    R2_Conditional = R2_conditional,
    KS_Unif = p_ks_uniformity,
    Dispersion = p_dispersion
  )
```

```{r}
#| label: tbl-validation-styled
#| tbl-cap: "Summary of Zero-Inflated Gamma models: ecological effect sizes, fit metrics, and DHARMa diagnostics."
#| eval: false
#| include: false

validation_summary %>%
  # Arrange by effect size to show the ecological gradient
  arrange(desc(Effect_Size)) %>%
  # Initialize kable
  kbl(
    digits = 3, 
    booktabs = TRUE,
    col.names = c("Taxon","N","DF", "Model Status", "Estimate", "SE", "p-value", "Sig", 
                  "Marginal", "Conditional", "KS Unif.", "Dispersion")
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE,
    latex_options = "scale_down"
  ) %>%
  # Emphasize significant ecological effects
  column_spec(3, bold = TRUE) %>%
  # Group columns for better scannability
  add_header_above(c(" " = 4, "Ecological effect (Pos. C)" = 4, 
                     "R² Metrics" = 2, "DHARMa P-values" = 2)) 
```

### Results Visualization

```{r}
#| label: fig-h1-forest-plot
#| fig-cap: "Effect of land use (Position C vs A) on population stability. Forest plot represents the log-ratio estimates of CV with 95% confidence intervals."
#| fig-width: 5
#| fig-height: 4
# Filter for the main effect of Position C on CV
plot_data_h1 <- model_summaries %>%
  filter(component == "cond", term == "positionC") %>%
  # Fix: Use a consistent string for Non-significant
  mutate(sig = ifelse(p.value < 0.05, "Significant", "Non-significant"),
         Manual_class = reorder(Manual_class, estimate))

p1 <- ggplot(plot_data_h1, aes(x = estimate, y = Manual_class, color = sig)) +
  geom_vline(xintercept = 0, color = "grey50", linewidth = 0.5) +
  # Using geom_errorbarh for horizontal bars
  geom_errorbarh(aes(xmin = estimate - (1.96 * std.error), 
                     xmax = estimate + (1.96 * std.error)), 
                 height = 0.2, linewidth = 0.8) +
  geom_point(size = 2) +
  # Fix: Match the string exactly here
  scale_color_manual(values = c("Significant" = "#ff6666", 
                                "Non-significant" = "#bcbcbc")) +
  scale_y_discrete(expand = expansion(mult = c(0.15, 0.05))) +
  theme_mee() +
  theme(legend.title = element_text(size = 4),         
    legend.text = element_text(size = 4),
    legend.key.size = unit(0.01, "cm"))+
  labs(x = "Estimate (log-link scale)", y =NULL,
       color = "Statistical status") +
  annotate("text", x = 0.5, y = 0.3, label = "Lower stability in C →", fontface = "italic", size = 2) +
  annotate("text", x = -0.5, y = 0.3, label = "← Lower stability in A", fontface = "italic", size = 2)

p1
tiff("../images_analysis/output/Fig.H1_population_stability_across_position.tiff", width = 1000, height = 1000, res = 300)
p1
invisible(dev.off())
```

## HYPOTHESIS 2: Technological Congruence

We replicate the analysis for model classified data to verify narrative consistency. We visualize the results on an Identity Plot : points falling on the dashed $y=x$ line represent perfect scientific agreement.

```{r}
#| label: model-class-pipeline

# Replicate Pipeline: Applies the exact same H1 logic to AI-classified data
stability_model_ai <- df_complete %>%
  group_by(Model_class) %>%
  filter(n() >= min_detections) %>%
  ungroup() %>%
  mutate(image_present_binary = !is.na(image_name)) %>%
  group_by(position, orientation, date, Model_class) %>%
  summarise(
    image_present = any(image_present_binary),
    activity = n_distinct(image_name, na.rm = TRUE), 
    .groups = "drop"
  ) %>%
  complete(Model_class, nesting(position, orientation, date, image_present), fill = list(activity = 0)) %>%
  mutate(activity_log = log1p(activity)) %>%
  group_by(Model_class, position, orientation) %>%
  nest() %>%
  mutate(rolling_data = map(data, ~compute_rolling_stability(.x, window_days = 7, max_missing = 0.05))) %>%
  unnest(rolling_data) %>%
  ungroup() %>%
  mutate(time_idx = as.numeric(as.factor(date))) %>%
  drop_na(date, position, Model_class)%>%
  filter(!Model_class %in% c("background", "multi_taxa", "unknown"))

# Fit AI-driven models to determine if the habitat narrative is preserved
taxon_analysis_ai <- stability_model_ai %>%
  group_by(Model_class) %>%
  nest() %>%
  mutate(model = map(data, possibly(fit_zig_model, otherwise = NULL))) %>%
  filter(!map_lgl(model, is.null))
```

```{r}
#| label: h2-comparison-stats

# Comparative Synthesis: Merges Manual and AI effect sizes to test congruence
res_manual <- taxon_analysis %>%
  mutate(tidied = map(model, tidy, effects = "fixed")) %>%
  unnest(tidied) %>%
  filter(component == "cond", term == "positionC") %>%
  select(Taxon = Manual_class, est_man = estimate, se_man = std.error)

res_ai <- taxon_analysis_ai %>%
  mutate(tidied = map(model, tidy, effects = "fixed")) %>%
  unnest(tidied) %>%
  filter(component == "cond", term == "positionC") %>%
  select(Taxon = Model_class, est_ai = estimate, se_ai = std.error)

# Congruence Calculation: Determines if estimates fall within mutual error bounds
h2_data <- inner_join(res_manual, res_ai, by = "Taxon") %>%
  mutate(
    diff = abs(est_man - est_ai))
```

```{r}
#| label: fig-h2-congruence
#| fig-cap: "Technological congruence (H2): Comparison of land-use effect sizes (Position C) between Human and AI pipelines. The dashed red line represents perfect identity (y=x). Error bars indicate ±1 SE."
#| fig-width: 5
#| fig-height: 4

p2 <- ggplot(h2_data, aes(x = est_man, y = est_ai)) +
  # Identity line (The target for congruence)
  geom_abline(slope = 1, intercept = 0,  color = "grey50", linewidth = 0.5) +
  
  # Error bars for both axes
  geom_errorbar(aes(ymin = est_ai - se_ai, ymax = est_ai + se_ai), color = "#ff6666", width = 0, linewidth = 0.5) +
  geom_errorbarh(aes(xmin = est_man - se_man, xmax = est_man + se_man), color = "#ff6666", height = 0, linewidth = 0.5) +
  # Taxon points
  geom_point(size = 2, color = "#ff6666") +
  ggrepel::geom_text_repel(aes(label = Taxon), size = 2, vjust = 0.3, hjust = 0.5) +
  theme_mee() +
  labs(
    x = "Human estimated effect",
    y = "Model estimated effect",
    color = "Estimate congruence"
  )

p2
tiff("../images_analysis/output/Fig.H2_technological_congruence.tiff", width = 1000, height = 1000, res = 300)
p2
invisible(dev.off())
```
